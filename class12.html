<!DOCTYPE HTML>
<html lang="en-US">
<head>
	<title>Class12</title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=1274, user-scalable=no">
	<meta name="description" content="Class12">
	<meta name="author" content="Yu-Ru Lin">
	<meta name="generator" content="slidify" />
	<!-- LOAD STYLE SHEETS -->
	<link rel="stylesheet" href="libraries/frameworks/shower/themes/ribbon/styles/screen.css">
	<link rel="stylesheet" media="print"
	  href="libraries/frameworks/shower/themes/ribbon/styles/print.css">
	<link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css">  <link rel="stylesheet" href = "assets/css/mystyle.css">
<link rel="stylesheet" href = "assets/css/ribbons.css">

	<!--
		To apply styles to the certain slides
		use slide ID to get needed elements
		-->
	<style>
		#Cover h2 {
      margin:65px 0 0;
			color:#FFF;
			text-align:center;
			font-size:70px;
			}
		#FitToWidth h2,
		#FitToHeight h2 {
			color:#FFF;
			text-align:center;
			}
	</style> 
</head>
<body class="list">
  <header class="caption">
  	<h1>Class12</h1>
	</header>
  <section class="slide " id="toc">
  <div>
    <h2>Class12</h2>
    <ul>
<li><a href="#set-up">Set up</a></li>
<li><a href="#big">Big data set</a></li>
<li><a href="#sparse">Sparse matrix</a></li>
<li><a href="#featureselection">Feature selection</a></li>
<li><a href="#freq">Frequent patterns</a></li>
</ul>

  </div>
</section>
<section class="slide modal" id="set-up">
  <div>
    <h2>Install R packages</h2>
    <pre><code class="r">## this tutorial uses the following packages
install.packages(&#39;sqldf&#39;)
install.packages(&#39;FSelector&#39;)
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="big">
  <div>
    <h2>Big data set</h2>
    <ul>
<li>When dealing with big data files, do not read everything into memory.</li>
<li>We use the sample data from: <a href="http://grouplens.org/datasets/hetrec-2011/">http://grouplens.org/datasets/hetrec-2011/</a></li>
<li>See: <a href="http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-readme.txt">http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-readme.txt</a></li>
</ul>

<pre><code class="r">## give the input filename
data.path = &#39;hetrec2011&#39;
ifilename = sprintf(&#39;%s/movies.dat&#39;,data.path)
## read the first n=3 lines
lines = readLines(ifilename,n=3)
lines
</code></pre>

<pre><code>## [1] &quot;id\ttitle\timdbID\tspanishTitle\timdbPictureURL\tyear\trtID\trtAllCriticsRating\trtAllCriticsNumReviews\trtAllCriticsNumFresh\trtAllCriticsNumRotten\trtAllCriticsScore\trtTopCriticsRating\trtTopCriticsNumReviews\trtTopCriticsNumFresh\trtTopCriticsNumRotten\trtTopCriticsScore\trtAudienceRating\trtAudienceNumRatings\trtAudienceScore\trtPictureURL&quot;
## [2] &quot;1\tToy story\t0114709\tToy story (juguetes)\thttp://ia.media-imdb.com/images/M/MV5BMTMwNDU0NTY2Nl5BMl5BanBnXkFtZTcwOTUxOTM5Mw@@._V1._SX214_CR0,0,214,314_.jpg\t1995\ttoy_story\t9\t73\t73\t0\t100\t8.5\t17\t17\t0\t100\t3.7\t102338\t81\thttp://content7.flixster.com/movie/10/93/63/10936393_det.jpg&quot;                                                     
## [3] &quot;2\tJumanji\t0113497\tJumanji\thttp://ia.media-imdb.com/images/M/MV5BMzM5NjE1OTMxNV5BMl5BanBnXkFtZTcwNDY2MzEzMQ@@._V1._SY314_CR3,0,214,314_.jpg\t1995\t1068044-jumanji\t5.6\t28\t13\t15\t46\t5.8\t5\t2\t3\t40\t3.2\t44587\t61\thttp://content8.flixster.com/movie/56/79/73/5679734_det.jpg&quot;
</code></pre>

  </div>
</section>
<section class="slide ssscode-nowrap compact" id="slide-4">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">## read the first 3 rows into a data.frame object
df = read.csv(ifilename, sep=&#39;\t&#39;, nrows=3) ## we saw from the first few lines that the field separator is &lt;TAB&gt;
df
</code></pre>

<pre><code>##   id          title imdbID           spanishTitle
## 1  1      Toy story 114709   Toy story (juguetes)
## 2  2        Jumanji 113497                Jumanji
## 3  3 Grumpy Old Men 107050 Dos viejos gru\xf1ones
##                                                                                                     imdbPictureURL
## 1 http://ia.media-imdb.com/images/M/MV5BMTMwNDU0NTY2Nl5BMl5BanBnXkFtZTcwOTUxOTM5Mw@@._V1._SX214_CR0,0,214,314_.jpg
## 2 http://ia.media-imdb.com/images/M/MV5BMzM5NjE1OTMxNV5BMl5BanBnXkFtZTcwNDY2MzEzMQ@@._V1._SY314_CR3,0,214,314_.jpg
## 3     http://ia.media-imdb.com/images/M/MV5BMTI5MTgyMzE0OF5BMl5BanBnXkFtZTYwNzAyNjg5._V1._SX214_CR0,0,214,314_.jpg
##   year            rtID rtAllCriticsRating rtAllCriticsNumReviews
## 1 1995       toy_story                9.0                     73
## 2 1995 1068044-jumanji                5.6                     28
## 3 1993  grumpy_old_men                5.9                     36
##   rtAllCriticsNumFresh rtAllCriticsNumRotten rtAllCriticsScore
## 1                   73                     0               100
## 2                   13                    15                46
## 3                   24                    12                66
##   rtTopCriticsRating rtTopCriticsNumReviews rtTopCriticsNumFresh
## 1                8.5                     17                   17
## 2                5.8                      5                    2
## 3                7.0                      6                    5
##   rtTopCriticsNumRotten rtTopCriticsScore rtAudienceRating
## 1                     0               100              3.7
## 2                     3                40              3.2
## 3                     1                83              3.2
##   rtAudienceNumRatings rtAudienceScore
## 1               102338              81
## 2                44587              61
## 3                10489              66
##                                                   rtPictureURL
## 1 http://content7.flixster.com/movie/10/93/63/10936393_det.jpg
## 2  http://content8.flixster.com/movie/56/79/73/5679734_det.jpg
## 3      http://content6.flixster.com/movie/25/60/256020_det.jpg
</code></pre>

  </div>
</section>
<section class="slide ssscode-nowrap compact" id="slide-5">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">## read row 101--103
df = read.csv(ifilename, sep=&#39;\t&#39;, nrows=3, skip=101, header=F) ## if we set &#39;header=T&#39;, the first non-skip row will be treated as header (which is incorrect)
df
</code></pre>

<pre><code>##    V1                            V2     V3                      V4
## 1 103                 Unforgettable 118040 Escondido en la memoria
## 2 104                 Happy Gilmore 116483             Terminagolf
## 3 105 The Bridges of Madison County 112579  Los puentes de Madison
##                                                                                                                 V5
## 1 http://ia.media-imdb.com/images/M/MV5BNDM1MDg5MzY4OV5BMl5BanBnXkFtZTcwMDM5NjgyMQ@@._V1._SY314_CR2,0,214,314_.jpg
## 2 http://ia.media-imdb.com/images/M/MV5BMjE1MzgxNjIyN15BMl5BanBnXkFtZTcwMjkzMjYyMQ@@._V1._SY314_CR6,0,214,314_.jpg
## 3 http://ia.media-imdb.com/images/M/MV5BMTQ5NzcyODM1Ml5BMl5BanBnXkFtZTcwODQwMDQyMQ@@._V1._SY314_CR6,0,214,314_.jpg
##     V6                        V7  V8 V9 V10 V11 V12 V13 V14 V15 V16 V17
## 1 1996             unforgettable 4.4 26   6  20  23 0.0   4   0   4   0
## 2 1996             happy_gilmore 5.5 50  29  21  58 5.1  11   4   7  36
## 3 1995 bridges_of_madison_county 7.2 40  36   4  90 7.9   9   9   0 100
##   V18    V19 V20
## 1 3.0    358  36
## 2 3.7 114875  83
## 3 3.6  11573  83
##                                                            V21
## 1 http://content8.flixster.com/movie/11/13/35/11133586_det.jpg
## 2      http://content7.flixster.com/movie/25/96/259613_det.jpg
## 3 http://content6.flixster.com/movie/10/92/73/10927328_det.jpg
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-6">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">## count how many lines in the file
# length(readLines(ifilename)) ## not recommended because it reads the file in memory
system(sprintf(&quot;wc -l %s&quot;,ifilename), intern=T ) 
</code></pre>

<pre><code>## [1] &quot;10198 hetrec2011/movies.dat&quot;
</code></pre>

<pre><code class="r">## you can use &#39;wc&#39; command on unix-based machine (linux, mac, etc.)

suppressWarnings(suppressPackageStartupMessages( ## avoid printing warnings
  require(R.utils)
)) ## assumig you have installed R.utils
countLines(ifilename)
</code></pre>

<pre><code>## [1] 10198
## attr(,&quot;lastLineHasNewline&quot;)
## [1] TRUE
</code></pre>

  </div>
</section>
<section class="slide scode compact" id="slide-7">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">suppressWarnings(suppressPackageStartupMessages( ## avoid printing warnings
  require(sqldf)
)) ## assumig you have installed sqldf
read.csv.sql(ifilename, &quot;select count(*) from file&quot;, sep=&#39;\t&#39;)
</code></pre>

<pre><code>##   count(*)
## 1    10197
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-8">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">sql = &#39;select id,title,year from file limit 1&#39; ## read 1 row
df = read.csv.sql(ifilename, sql, sep=&#39;\t&#39;)
df
</code></pre>

<pre><code>##   id     title year
## 1  1 Toy story 1995
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-9">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">sql = &#39;select id,title,year from file limit 10&#39; ## read 10 rows
df = read.csv.sql(ifilename, sql, sep=&#39;\t&#39;)
df
</code></pre>

<pre><code>##    id                       title year
## 1   1                   Toy story 1995
## 2   2                     Jumanji 1995
## 3   3              Grumpy Old Men 1993
## 4   4           Waiting to Exhale 1995
## 5   5 Father of the Bride Part II 1995
## 6   6                        Heat 1995
## 7   7                     Sabrina 1954
## 8   8                Tom and Huck 1995
## 9   9                Sudden Death 1995
## 10 10                   GoldenEye 1995
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-10">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">sql = &#39;select id,title,year from file limit 5,10&#39; 
## skip the first 5 rows, and read the next 10 rows
df = read.csv.sql(ifilename, sql, sep=&#39;\t&#39;)
df
</code></pre>

<pre><code>##    id                       title year
## 1   6                        Heat 1995
## 2   7                     Sabrina 1954
## 3   8                Tom and Huck 1995
## 4   9                Sudden Death 1995
## 5  10                   GoldenEye 1995
## 6  11      The American President 1995
## 7  12 Dracula: Dead and Loving It 1995
## 8  13                       Balto 1995
## 9  14                       Nixon 1995
## 10 15            Cutthroat Island 1995
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-11">
  <div>
    <h2>Big data set</h2>
    <pre><code class="r">sql = &#39;select year,count(*) from file group by year limit 10&#39; 
## you can do more if you are familiar with SQL 
df = read.csv.sql(ifilename, sql, sep=&#39;\t&#39;)
df
</code></pre>

<pre><code>##    year count(*)
## 1  1903        1
## 2  1915        1
## 3  1916        1
## 4  1917        2
## 5  1918        1
## 6  1919        3
## 7  1920        4
## 8  1921        2
## 9  1922        9
## 10 1923        4
</code></pre>

<ul>
<li>if you have mysql database, you can use &#39;RMySQL&#39; package.</li>
<li>Other tips (using &#39;fread&#39;): <a href="http://davetang.org/muse/2013/09/03/handling-big-data-in-r/">http://davetang.org/muse/2013/09/03/handling-big-data-in-r/</a></li>
</ul>

  </div>
</section>
<section class="slide scode-nowrap compact" id="sparse">
  <div>
    <h2>Sparse matrix</h2>
    <p>When dealing with big matrix, use sparse format to construct matrix.</p>

<pre><code class="r">ifilename = sprintf(&#39;%s/movies.dat&#39;,data.path)
movie.df = read.csv(ifilename, sep=&#39;\t&#39;)
dim(movie.df)
</code></pre>

<pre><code>## [1] 10197    21
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-13">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">movie.df[1:3,1:4] ## check a small part
</code></pre>

<pre><code>##   id          title imdbID           spanishTitle
## 1  1      Toy story 114709   Toy story (juguetes)
## 2  2        Jumanji 113497                Jumanji
## 3  3 Grumpy Old Men 107050 Dos viejos gru\xf1ones
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-14">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">ifilename = sprintf(&#39;%s/%s&#39;,data.path, &#39;movie_genres.dat&#39;)
m2g.df = read.csv(ifilename, sep=&#39;\t&#39;, header=T)
m2g.df[1:3,]
</code></pre>

<pre><code>##   movieID     genre
## 1       1 Adventure
## 2       1 Animation
## 3       1  Children
</code></pre>

<pre><code class="r">dim(m2g.df)
</code></pre>

<pre><code>## [1] 20809     2
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-15">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">m2g.df[1:10,] ## check a small part
</code></pre>

<pre><code>##    movieID     genre
## 1        1 Adventure
## 2        1 Animation
## 3        1  Children
## 4        1    Comedy
## 5        1   Fantasy
## 6        2 Adventure
## 7        2  Children
## 8        2   Fantasy
## 9        3    Comedy
## 10       3   Romance
</code></pre>

  </div>
</section>
<section class="slide sscode-nowrap compact" id="slide-16">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">## create a numeric index for genres, so that we can create a matrix
g = unique(as.character(m2g.df$genre))
length(g) ## how many genres?
</code></pre>

<pre><code>## [1] 20
</code></pre>

<pre><code class="r">m = unique(as.character(m2g.df$movieID))
length(m) ## how many movies?
</code></pre>

<pre><code>## [1] 10197
</code></pre>

<pre><code class="r">idx2g = match(as.character(m2g.df$genre),g)
idx2g[1:20]; length(idx2g)
</code></pre>

<pre><code>##  [1]  1  2  3  4  5  1  3  5  4  6  4  7  6  4  8  9 10  4  6  1
</code></pre>

<pre><code>## [1] 20809
</code></pre>

<pre><code class="r">idx2m = match(as.character(m2g.df$movieID),m)
idx2m[1:20]; length(idx2m)
</code></pre>

<pre><code>##  [1] 1 1 1 1 1 2 2 2 3 3 4 4 4 5 6 6 6 7 7 8
</code></pre>

<pre><code>## [1] 20809
</code></pre>

  </div>
</section>
<section class="slide sscode-nowrap compact" id="slide-17">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">require(Matrix);require(MASS)
## construct a movie-to-genre sparse matrix; the format is (i,j,v), meaning entry(i,j)=v
m2g = sparseMatrix(i=idx2m,j=idx2g,x=rep(1,nrow(m2g.df)) )
dim(m2g)
</code></pre>

<pre><code>## [1] 10197    20
</code></pre>

<pre><code class="r">object.size(m2g)
</code></pre>

<pre><code>## 251256 bytes
</code></pre>

<pre><code class="r">print(object.size(m2g),units=&quot;Mb&quot;)  ## gives you size of the object in Mb
</code></pre>

<pre><code>## 0.2 Mb
</code></pre>

<pre><code class="r">## report current memory used by R, e.g., __ Mb in my machine
# print(object.size(x=lapply(ls(), get)), units=&quot;Mb&quot;) 
denseM2G = as.matrix(m2g) ## dense matrix
print(object.size(denseM2G),units=&quot;Mb&quot;) 
</code></pre>

<pre><code>## 1.6 Mb
</code></pre>

<pre><code class="r">## report current memory used by R, e.g., __ Mb in my machine
print(object.size(x=lapply(ls(), get)), units=&quot;Mb&quot;) 
</code></pre>

<pre><code>## 18 Mb
</code></pre>

<pre><code class="r">rm(denseM2G)
## report current memory used by R, e.g., __ Mb in my machine
print(object.size(x=lapply(ls(), get)), units=&quot;Mb&quot;)
</code></pre>

<pre><code>## 16.5 Mb
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-18">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">m2g[1:3,]
</code></pre>

<pre><code>## 3 x 20 sparse Matrix of class &quot;dgCMatrix&quot;
##                                             
## [1,] 1 1 1 1 1 . . . . . . . . . . . . . . .
## [2,] 1 . 1 . 1 . . . . . . . . . . . . . . .
## [3,] . . . 1 . 1 . . . . . . . . . . . . . .
</code></pre>

  </div>
</section>
<section class="slide sscode-nowrap compact" id="slide-19">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">S = svd(m2g, nu=3, nv=3)
S$d;dim(S$u);dim(S$v)
</code></pre>

<pre><code>##  [1] 80.339162 56.217046 47.467550 37.381261 35.152986 32.417355 28.714880
##  [8] 26.351900 23.990882 22.435821 21.516690 20.879957 20.437864 19.828438
## [15] 18.852950 15.975737 13.271108 11.726427  4.911211  1.000000
</code></pre>

<pre><code>## [1] 10197     3
</code></pre>

<pre><code>## [1] 20  3
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-20">
  <div>
    <h2>Sparse matrix</h2>
    <pre><code class="r">## if the matrix is very big, you can use package irlba to compute approximate SVD
## this has been tested in Netflix matrix!
require(irlba)
S = irlba(m2g, nu=3, nv=3)
S$d;dim(S$u);dim(S$v)
</code></pre>

<pre><code>## [1] 80.33916 56.21705 47.46755
</code></pre>

<pre><code>## [1] 10197     3
</code></pre>

<pre><code>## [1] 20  3
</code></pre>

<pre><code class="r">system.time({S = irlba(m2g, nu=5, nv=5)}) ## report the running time
</code></pre>

<pre><code>##    user  system elapsed 
##   0.540   0.032   0.565
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="featureselection">
  <div>
    <h2>Feature selection</h2>
    <ul>
<li>With feature selection, you can reduce the dimension and complexity of future steps on the Data Mining process.</li>
<li>Examples adopted from: <a href="http://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Dimensionality_Reduction/Feature_Selection">http://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Dimensionality_Reduction/Feature_Selection</a></li>
</ul>

<pre><code class="r">require(FSelector) 
## assumig you have installed FSelector
## installation note: requires Java installed on your machine and the rJava package

## load a dataset and use it as the main source of data
require(mlbench)
data(HouseVotes84)
HouseVotes84[1:3,]
</code></pre>

<pre><code>##        Class   V1 V2 V3   V4 V5 V6 V7 V8 V9 V10  V11 V12 V13 V14 V15  V16
## 1 republican    n  y  n    y  y  y  n  n  n   y &lt;NA&gt;   y   y   y   n    y
## 2 republican    n  y  n    y  y  y  n  n  n   n    n   y   y   y   n &lt;NA&gt;
## 3   democrat &lt;NA&gt;  y  y &lt;NA&gt;  y  y  n  n  n   n    y   n   y   y   n    n
</code></pre>

  </div>
</section>
<section class="slide ssscode-nowrap compact" id="slide-22">
  <div>
    <h2>Feature selection</h2>
    <pre><code class="r">## Feature Ranking --
## calculate weights for each atribute using some function
weights = chi.squared(Class~., HouseVotes84)
## the weights can be given by different functions: Pearson&#39;s correlation (linear.correlation), Spearman&#39;s correlation (rank.correlation), Chi-squared Filter (chi.squared), Information Gain (information.gain), etc.
print(weights)
</code></pre>

<pre><code>##     attr_importance
## V1      0.409330348
## V2      0.004534049
## V3      0.748864321
## V4      0.923255954
## V5      0.718768923
## V6      0.428332508
## V7      0.521967369
## V8      0.661876085
## V9      0.629797943
## V10     0.083809300
## V11     0.378240781
## V12     0.714922593
## V13     0.555971176
## V14     0.625283342
## V15     0.538263037
## V16     0.353273580
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-23">
  <div>
    <h2>Feature selection</h2>
    <pre><code class="r">## select a subset of 5 features with the lowest weight
subset = cutoff.k(weights, 5)

## print the results
f = as.simple.formula(subset, &quot;Class&quot;)
print(f)
</code></pre>

<pre><code>## Class ~ V4 + V3 + V5 + V12 + V8
## &lt;environment: 0x136f5e98&gt;
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-24">
  <div>
    <h2>Feature selection</h2>
    <pre><code class="r">## Feature Subset Selection (Wrappers) --
library(rpart)
data(iris)
iris[1:3,]
</code></pre>

<pre><code>##      species sepal.len sepal.wid petal.len petal.wid
## 1 versicolor       7.0       3.2       4.7       1.4
## 2 versicolor       6.4       3.2       4.5       1.5
## 3 versicolor       6.9       3.1       4.9       1.5
</code></pre>

  </div>
</section>
<section class="slide ssscode-nowrap compact" id="slide-25">
  <div>
    <h2>Feature selection</h2>
    <pre><code class="r">## define the evaluation function  
evaluator &lt;- function(subset) {
  #here you must define a function that returns a double value to evaluate the given subset
  #consider high values for good evaluation and low values for bad evaluation.
  #k-fold cross validation
  k &lt;- 4
  splits &lt;- runif(nrow(iris))
  results = sapply(1:k, function(i) {
    test.idx &lt;- (splits &gt;= (i - 1) / k) &amp; (splits &lt; i / k)
    train.idx &lt;- !test.idx
    test &lt;- iris[test.idx, , drop=FALSE]
    train &lt;- iris[train.idx, , drop=FALSE]
    tree &lt;- rpart(as.simple.formula(subset, &quot;species&quot;), train)
    error.rate = sum(test$species != predict(tree, test, type=&quot;c&quot;)) / nrow(test)
    return(1 - error.rate)
  })
  print(as.simple.formula(subset, &quot;species&quot;))
#   print(subset)
  print(mean(results))
  return(mean(results))
}
</code></pre>

  </div>
</section>
<section class="slide ssscode-nowrap compact" id="slide-26">
  <div>
    <h2>Feature selection</h2>
    <pre><code class="r">## perform the best subset search
subset = best.first.search(names(iris)[-5], evaluator)
</code></pre>

<pre><code>## Error in 1:numclass: result would be too long a vector
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-27">
  <div>
    <h2>Feature selection</h2>
    <pre><code class="r">## you can use different strategy for search the optimal subset: Best First Search (best.first.search), Exhaustive Search (exhaustive.search), Greedy Search (forward.search, backward.search), etc.

## prints the result
f = as.simple.formula(subset, &quot;species&quot;)
print(f)
</code></pre>

<pre><code>## species ~ V4 + V3 + V5 + V12 + V8
## &lt;environment: 0x15e92be8&gt;
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="freq">
  <div>
    <h2>Frequent patterns</h2>
    <pre><code class="r">library(arules) ## assumig you have installed arules
cat(readLines(&quot;sample-data/toy-transaction.txt&quot;),sep=&#39;\n&#39;) 
</code></pre>

<pre><code>## A,B,C
## B,C
## A,B,D
## A,B,C,D
## A
## B
</code></pre>

<pre><code class="r">## see what&#39;s inside the toy transactions
</code></pre>

  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-29">
  <div>
    <h2>Frequent patterns</h2>
    
  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-30">
  <div>
    <h2>Frequent patterns</h2>
    
  </div>
</section>
<section class="slide scode-nowrap compact" id="slide-31">
  <div>
    <h2>Frequent patterns</h2>
    
  </div>
</section>
  <div class="progress">
    <div></div>
  </div>
    <footer class = 'foot'>
      <a href="index.html"><img src = 'assets/img/arrow_up_circle.png' style="width:30px;height:30px;"></a></img>
      <a href="#toc"><img src = 'assets/img/circle-info.png' style="width:32px;height:32px;"></a></img>
    </footer>    
	<script src="libraries/frameworks/shower/shower.js"></script>
	<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	    tex2jax: {
	      inlineMath: [['$','$'], ['\\(','\\)']],
	      processEscapes: true
	    }
	  });
	</script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script> -->
	<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
	<script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>
	<!-- DONE LOADING HIGHLIGHTER JS FILES -->
	 
		<!-- Copyright © 2010–2012 Vadim Makeev — pepelsbey.net -->
	<!-- Photos by John Carey — fiftyfootshadows.net -->
</body>
</html>