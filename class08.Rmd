---
title       : Class08
subtitle    : Text Mining
author      : Yu-Ru Lin
job         : 
framework   : shower        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
toc         : true
toc_depth   : 2

--- #toc
## Class08
  
* [Set up](#set-up)
* [Text processing](#text)
* [LSA](#lsa)
* [LDA](#lda)
* [NMF](#nmf)
* [Text classification](#textclassify)

--- #set-up .modal 

## Install R packages
```{r, eval=FALSE}
## this tutorial uses the following packages
```

--- #text .sscode-nowrap .compact
## Text processing
```{r}
## load libraries
library(tm)
library(lsa)
library(ggplot2)

## prepare a toy example with 9 documents in three topics: big data, global warming, government shutdown
text = c(
  "With all the buzz surrounding big data, the data management practitioner is constantly inundated with information regarding big data technologies.",
  "We create so much data every day that 90 percent of the information in the world today has been created in the last two years alone, according to IBM.",
  "Random algorithms and probabilistic data structures are algorithmically efficient and can provide shockingly good practical results.",
  "Scientists will issue their starkest warning yet about the mounting dangers of global warming.",
  "Scientists are more certain than ever that humans are causing the majority of climate change, a major new report has shown.",
  "There's a consensus among leading scientists that global warming is caused by human activity.",
  "The mood in financial markets was cautious on Monday as the partial shut-down of the American government entered a seventh day and lawmakers appeared to be making little headway in raising the country's debt ceiling.",
  "President Obama must continue to refuse to negotiate policy while the government is shut down. ",
  "The stock market is closing at its lowest level in a month as the U.S. government enters a second week of being partially shut down."
)
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
## give the topic labels
topic = factor(rep(c("big data", "global warming", "gov shutdown"), each = 3))
df = data.frame(text, topic, stringsAsFactors = FALSE)
df[1:3,]
dim(df)
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
## prepare corpus
corpus = Corpus(VectorSource(df$text))
corpus = tm_map(corpus, tolower) ## convert text to lower case
inspect(corpus[1:3])  
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
corpus = tm_map(corpus, removePunctuation) ## remove punctuations
inspect(corpus[1:3]) 
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
corpus = tm_map(corpus, removeNumbers) ## remove numbers
inspect(corpus[1:3]) 
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
corpus = tm_map(corpus, function(x) removeWords(x, stopwords("english"))) ## remove stopwords
inspect(corpus[1:3]) 
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
corpus = tm_map(corpus, stemDocument, language = "english") ## stemming
inspect(corpus[1:3])
corpus  # check corpus
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
td.mat = as.matrix(TermDocumentMatrix(corpus))
td.mat[1:3,]
dim(td.mat) ## dimension of term-doc matrix
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
dist.mat = dist(t(as.matrix(td.mat))) ## compute distance matrix
dist.mat  ## check distance matrix
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1), fig.width=6, fig.height=4}
## generate mds plot
doc.mds = cmdscale(dist.mat, k = 2)
data = data.frame(x = doc.mds[, 1], y = doc.mds[, 2], topic = df$topic, id = row.names(df))
ggplot(data, aes(x = x, y = y, color=topic)) + 
  geom_point() + geom_text(aes(x = x, y = y - 0.2, label = id))
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1), fig.width=6, fig.height=4}
td.mat.w = lw_tf(td.mat) * gw_idf(td.mat)  ## tf-idf weighting
dist.mat = dist(t(as.matrix(td.mat.w))) ## compute distance matrix

## generate mds plot using new distance matrix
doc.mds = cmdscale(dist.mat, k = 2)
data = data.frame(x = doc.mds[, 1], y = doc.mds[, 2], topic = df$topic, id = row.names(df))
ggplot(data, aes(x = x, y = y, color=topic)) + 
  geom_point() + geom_text(aes(x = x, y = y - 0.2, label = id))
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
## generate wordcloud
library(wordcloud)
m = as.matrix(td.mat)
## calculate the frequency of words
v = sort(rowSums(m), decreasing=TRUE) 
words = names(v)
wc = data.frame(word=words, freq=v)
wc[1:3,]
```

--- .sscode-nowrap .compact
## Text processing
```{r, dependson=c(-1)}
wordcloud(wc$word, wc$freq, min.freq=2)
```

--- #lsa .sscode-nowrap .compact
## LSA
```{r, dependson=c(-1)}
## compute svd (do lsa manually)
k = 3
S = svd(as.matrix(td.mat.w),nu=k,nv=k)
u = S$u; s = S$d; v = S$v
td.mat.svd = S$u %*% diag(S$d[1:k]) %*% t(S$v) ## X ~ U * S * V^t
dist.mat = dist(t(td.mat.svd))
doc.mds = cmdscale(dist.mat, k = 2)
data = data.frame(x = doc.mds[, 1], y = doc.mds[, 2], topic = df$topic, id = row.names(df))
ggplot(data, aes(x = x, y = y, color=topic)) + 
  geom_point() + geom_text(aes(x = x, y = y - 0.2, label = id))
```

--- .sscode-nowrap .compact
## LSA
```{r, dependson=c(-1)}
## run mds by lsa package
lsa.space = lsa(td.mat.w,dims=3)  ## create LSA space
dist.mat = dist(t(as.textmatrix(lsa.space)))  ## compute distance matrix
dist.mat  ## check distance mantrix
```

--- .sscode-nowrap .compact
## LSA
```{r, dependson=c(-1)}
doc.mds = cmdscale(dist.mat, k = 2)
data = data.frame(x = doc.mds[, 1], y = doc.mds[, 2], topic = df$topic, id = row.names(df))
ggplot(data, aes(x = x, y = y, color=topic)) + 
  geom_point() + geom_text(aes(x = x, y = y - 0.2, label = id))
```

--- .sscode-nowrap .compact
## LSA
```{r, dependson=c(-1)}
## generate 3d plot
library(scatterplot3d)
doc.mds = cmdscale(dist.mat, k = 3)
colors = rep(c("blue", "green", "red"), each = 3)
scatterplot3d(doc.mds[, 1], doc.mds[, 2], doc.mds[, 3], color = colors, 
              pch = 16, main = "Semantic Space Scaled to 3D", xlab = "x", ylab = "y", 
              zlab = "z", type = "h")
```

--- .sscode-nowrap .compact #lda
## LDA
```{r, dependson=c(-1)}
## run LDA topic model
library(topicmodels)
lda = LDA(t(td.mat), 3)
terms(lda)
topics(lda)
```

--- .sscode-nowrap .compact
## LDA
```{r, dependson=c(-1)}
terms <- as.data.frame(t(posterior(lda)$terms))
head(terms)
```

--- .sscode-nowrap .compact
## LDA
```{r, dependson=c(-1)}
topics <- as.data.frame(t(posterior(lda)$topics))
head(topics)
```

--- .sscode-nowrap .compact #nmf
## NMF
```{r, dependson=c(-1)}
## run NMF
library(NMF)
# V ~ WH' 
# V is an n x p matrix
# W = n x r  term feature matrix
# H = r x p  doc feature matrix
set.seed(12345)
res = nmf(td.mat, 3,"lee") # lee & seung method
V.hat = fitted(res) 
dim(V.hat) ## estimated target matrix
```

--- .sscode-nowrap .compact 
## NMF
```{r, dependson=c(-1)}
w = basis(res) ##  W  term feature matrix matrix
dim(w) # n x r (n=95, r=3)
```

--- .sscode-nowrap .compact 
## NMF
```{r, dependson=c(-1)}
h = coef(res) ## H  doc feature matrix
dim(h) #  r x p (r=3, p=9)
```

--- .sscode-nowrap .compact 
## NMF
```{r, dependson=c(-1)}
doc2 = data.frame(t(h))
features = cbind(doc2$X1,doc2$X2,doc2$X3)
scatterplot3d(features[, 1], features[, 2], features[, 3], color = colors, 
              pch = 16, main = "Semantic Space Scaled to 3D", xlab = "x", ylab = "y", 
              zlab = "z", type = "h")
```